package migrator

import (
	"context"
	"database/sql"
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"time"

	"ariga.io/atlas/sql/schema"
	"github.com/eleven-am/storm/internal/generator"
	"github.com/eleven-am/storm/internal/parser"
)

// MigrationOptions contains options for migration generation
type MigrationOptions struct {
	PackagePath         string
	OutputDir           string
	MigrationName       string
	DryRun              bool
	AllowDestructive    bool
	PushToDB            bool
	CreateDBIfNotExists bool
}

// MigrationResult contains the results of migration generation
type MigrationResult struct {
	UpSQL          string
	DownSQL        string
	Changes        []schema.Change
	HasDestructive bool
	DestructiveOps []string
	UpFilePath     string
	DownFilePath   string
}

// AtlasMigrator handles migration generation using Atlas with simplified approach
type AtlasMigrator struct {
	config            *DBConfig
	tempDBManager     *TempDBManager
	structParser      *parser.StructParser
	schemaGenerator   *generator.SchemaGenerator
	sqlGenerator      *generator.SQLGenerator
	migrationReverser *MigrationReverser
}

func NewAtlasMigrator(config *DBConfig) *AtlasMigrator {
	return &AtlasMigrator{
		config:            config,
		tempDBManager:     NewTempDBManager(config),
		structParser:      parser.NewStructParser(),
		schemaGenerator:   generator.NewSchemaGenerator(),
		sqlGenerator:      generator.NewSQLGenerator(),
		migrationReverser: NewMigrationReverser(),
	}
}

func (m *AtlasMigrator) GenerateMigration(ctx context.Context, sourceDB *sql.DB, opts MigrationOptions) (*MigrationResult, error) {

	fmt.Println("Parsing Go structs...")
	models, err := m.structParser.ParseDirectory(opts.PackagePath)
	if err != nil {
		return nil, fmt.Errorf("failed to parse structs: %w", err)
	}
	fmt.Printf("Found %d models in %s\n", len(models), opts.PackagePath)

	fmt.Println("Generating DDL SQL from Go structs...")
	schema, err := m.schemaGenerator.GenerateSchema(models)
	if err != nil {
		return nil, fmt.Errorf("failed to generate schema: %w", err)
	}

	ddlSQL := m.sqlGenerator.GenerateSchema(schema)
	fmt.Printf("Generated DDL for %d tables\n", len(schema.Tables))

	simpleMigrator := NewSimplifiedAtlasMigrator(m.config)
	upStatements, changes, err := simpleMigrator.GenerateMigrationSimple(ctx, sourceDB, ddlSQL, opts.CreateDBIfNotExists)
	if err != nil {
		return nil, fmt.Errorf("failed to generate migration: %w", err)
	}

	if len(changes) == 0 {
		fmt.Println("No schema changes detected! Database is up to date.")
		return &MigrationResult{}, nil
	}

	fmt.Printf("Found %d migration statements:\n", len(changes))

	destructiveCount, destructiveOps := CountDestructiveChanges(changes)

	var upBuilder strings.Builder
	upBuilder.WriteString("-- Migration UP generated by db-migrator using Atlas\n")
	upBuilder.WriteString("-- Generated at: " + time.Now().UTC().Format(time.RFC3339) + "\n\n")

	// Add database creation if requested (but not for push, as it's handled separately)
	if opts.CreateDBIfNotExists && !opts.PushToDB {
		if dbName := extractDatabaseName(m.config.URL); dbName != "" {
			upBuilder.WriteString("-- Create database if it doesn't exist\n")
			upBuilder.WriteString(fmt.Sprintf("CREATE DATABASE IF NOT EXISTS %s;\n\n", quoteIdentifier(dbName)))
		}
	}

	// Check if CUID functions are needed and add them if so
	if needsCUIDFunctions(upStatements) {
		upBuilder.WriteString(generateCUIDFunctions())
		upBuilder.WriteString("\n")
	}

	for i, stmt := range upStatements {
		var description string
		if i < len(changes) {
			description = DescribeChange(changes[i])
		} else {
			description = "Generated statement"
		}
		upBuilder.WriteString(fmt.Sprintf("-- Statement %d: %s\n", i+1, description))
		upBuilder.WriteString(stmt)
		if !strings.HasSuffix(stmt, ";") {
			upBuilder.WriteString(";")
		}
		upBuilder.WriteString("\n\n")
	}

	var downBuilder strings.Builder
	downBuilder.WriteString("-- Migration DOWN generated by db-migrator using Atlas\n")
	downBuilder.WriteString("-- Generated at: " + time.Now().UTC().Format(time.RFC3339) + "\n\n")
	downBuilder.WriteString("-- WARNING: Reverse migration may cause data loss!\n")
	downBuilder.WriteString("-- Review carefully before executing.\n\n")

	for i := len(upStatements) - 1; i >= 0; i-- {
		reversed, err := m.migrationReverser.ReverseSQL(upStatements[i])
		if err != nil {
			downBuilder.WriteString(fmt.Sprintf("-- ERROR: Failed to reverse statement %d: %v\n", i+1, err))
			downBuilder.WriteString(fmt.Sprintf("-- Original: %s\n\n", upStatements[i]))
		} else if reversed != "" {
			downBuilder.WriteString(fmt.Sprintf("-- Reversal of statement %d\n", i+1))
			downBuilder.WriteString(reversed)
			if !strings.HasSuffix(reversed, ";") {
				downBuilder.WriteString(";")
			}
			downBuilder.WriteString("\n\n")
		}
	}

	upSQL := upBuilder.String()
	downSQL := downBuilder.String()

	result := &MigrationResult{
		UpSQL:          upSQL,
		DownSQL:        downSQL,
		Changes:        changes,
		HasDestructive: destructiveCount > 0,
		DestructiveOps: destructiveOps,
	}

	if result.HasDestructive && !opts.AllowDestructive {
		fmt.Println("\nPOTENTIALLY DESTRUCTIVE OPERATIONS DETECTED:")
		for _, op := range destructiveOps {
			fmt.Printf("  - %s\n", op)
		}
		fmt.Println("\nUse --allow-destructive to proceed with these changes.")
		fmt.Println("Review the changes carefully as they may cause data loss.")
		return result, nil
	}

	if opts.DryRun {
		fmt.Println("\n=== UP Migration ===")
		fmt.Println(upSQL)
		fmt.Println("\n=== DOWN Migration ===")
		fmt.Println(downSQL)
		return result, nil
	}

	if opts.PushToDB {
		fmt.Println("Executing migration on database...")

		// Prepare statements for execution, including CUID functions if needed
		var execStatements []string

		// Add CUID functions first if needed
		if needsCUIDFunctions(upStatements) {
			cuidSQL := generateCUIDFunctions()
			// Execute CUID functions as a single block to handle dollar-quoted strings properly
			fmt.Printf("Executing CUID functions...\n")
			if _, err := sourceDB.ExecContext(ctx, cuidSQL); err != nil {
				return nil, fmt.Errorf("failed to execute CUID functions: %w", err)
			}
		}

		// Add the main migration statements
		execStatements = append(execStatements, upStatements...)

		// Execute all statements
		for i, stmt := range execStatements {
			fmt.Printf("Executing statement %d/%d...\n", i+1, len(execStatements))
			if _, err := sourceDB.ExecContext(ctx, stmt); err != nil {
				return nil, fmt.Errorf("failed to execute statement %d: %s\nError: %w", i+1, stmt, err)
			}
		}
		fmt.Printf("\nMigration executed successfully! Applied %d changes.\n", len(execStatements))
		return result, nil
	}

	if opts.OutputDir != "" {
		if err := m.writeMigrationFiles(opts.OutputDir, opts.MigrationName, upSQL, downSQL); err != nil {
			return nil, fmt.Errorf("failed to write migration files: %w", err)
		}

		timestamp := time.Now().UTC().Format("20060102150405")
		migrationName := opts.MigrationName
		if migrationName == "" {
			migrationName = "schema_update"
		}
		baseName := fmt.Sprintf("%s_%s", timestamp, migrationName)
		result.UpFilePath = filepath.Join(opts.OutputDir, fmt.Sprintf("%s.up.sql", baseName))
		result.DownFilePath = filepath.Join(opts.OutputDir, fmt.Sprintf("%s.down.sql", baseName))

		fmt.Printf("\nMigration files created:\n")
		fmt.Printf("  UP:   %s\n", result.UpFilePath)
		fmt.Printf("  DOWN: %s\n", result.DownFilePath)
	}

	return result, nil
}

func (m *AtlasMigrator) writeMigrationFiles(outputDir, migrationName, upSQL, downSQL string) error {

	if err := os.MkdirAll(outputDir, 0755); err != nil {
		return fmt.Errorf("failed to create output directory: %w", err)
	}

	timestamp := time.Now().UTC().Format("20060102150405")
	if migrationName == "" {
		migrationName = "schema_update"
	}

	baseName := fmt.Sprintf("%s_%s", timestamp, migrationName)
	upFile := filepath.Join(outputDir, fmt.Sprintf("%s.up.sql", baseName))
	downFile := filepath.Join(outputDir, fmt.Sprintf("%s.down.sql", baseName))

	if err := os.WriteFile(upFile, []byte(upSQL), 0644); err != nil {
		return fmt.Errorf("failed to write UP migration: %w", err)
	}

	if err := os.WriteFile(downFile, []byte(downSQL), 0644); err != nil {
		return fmt.Errorf("failed to write DOWN migration: %w", err)
	}

	return nil
}

// needsCUIDFunctions checks if any SQL statements contain gen_cuid() function calls
func needsCUIDFunctions(statements []string) bool {
	for _, stmt := range statements {
		if strings.Contains(strings.ToLower(stmt), "gen_cuid()") {
			return true
		}
	}
	return false
}

// generateCUIDFunctions returns the SQL for creating CUID generation functions
func generateCUIDFunctions() string {
	var sql strings.Builder

	sql.WriteString("-- CUID generation functions\n")
	sql.WriteString("-- These functions provide collision-resistant unique identifier generation\n\n")

	// Enable pgcrypto extension for digest function
	sql.WriteString("-- Enable pgcrypto extension for cryptographic functions\n")
	sql.WriteString("CREATE EXTENSION IF NOT EXISTS pgcrypto;\n\n")

	// Create sequence for CUID counter
	sql.WriteString("-- Create sequence for CUID counter if it doesn't exist\n")
	sql.WriteString("CREATE SEQUENCE IF NOT EXISTS cuid_counter_seq;\n\n")

	// Base36 encoding function
	sql.WriteString("-- Base36 encoding function for CUID generation\n")
	sql.WriteString("CREATE OR REPLACE FUNCTION to_base36(num BIGINT) RETURNS TEXT AS $$\n")
	sql.WriteString("DECLARE\n")
	sql.WriteString("    v_base36 TEXT := '0123456789abcdefghijklmnopqrstuvwxyz';\n")
	sql.WriteString("    v_result TEXT := '';\n")
	sql.WriteString("    v_remainder INT;\n")
	sql.WriteString("BEGIN\n")
	sql.WriteString("    IF num = 0 THEN\n")
	sql.WriteString("        RETURN '0';\n")
	sql.WriteString("    END IF;\n")
	sql.WriteString("    \n")
	sql.WriteString("    WHILE num > 0 LOOP\n")
	sql.WriteString("        v_remainder := num % 36;\n")
	sql.WriteString("        v_result := substr(v_base36, v_remainder + 1, 1) || v_result;\n")
	sql.WriteString("        num := num / 36;\n")
	sql.WriteString("    END LOOP;\n")
	sql.WriteString("    \n")
	sql.WriteString("    RETURN v_result;\n")
	sql.WriteString("END;\n")
	sql.WriteString("$$ LANGUAGE plpgsql IMMUTABLE;\n\n")

	// Main CUID generation function
	sql.WriteString("-- Production-ready CUID generator function\n")
	sql.WriteString("CREATE OR REPLACE FUNCTION gen_cuid() RETURNS CHAR(25) AS $$\n")
	sql.WriteString("DECLARE\n")
	sql.WriteString("    v_timestamp BIGINT;\n")
	sql.WriteString("    v_counter BIGINT;\n")
	sql.WriteString("    v_fingerprint TEXT;\n")
	sql.WriteString("    v_random TEXT;\n")
	sql.WriteString("    v_result TEXT := 'c';\n")
	sql.WriteString("BEGIN\n")
	sql.WriteString("    v_timestamp := FLOOR(EXTRACT(EPOCH FROM clock_timestamp()) * 1000);\n")
	sql.WriteString("    \n")
	sql.WriteString("    v_counter := nextval('cuid_counter_seq');\n")
	sql.WriteString("    \n")
	sql.WriteString("    -- Handle potential NULL from inet_server_addr()\n")
	sql.WriteString("    v_fingerprint := encode(digest(current_database() || COALESCE(inet_server_addr()::TEXT, 'localhost'), 'sha256'), 'hex');\n")
	sql.WriteString("    \n")
	sql.WriteString("    v_result := v_result || lpad(to_base36(v_timestamp), 8, '0');\n")
	sql.WriteString("    \n")
	sql.WriteString("    v_result := v_result || lpad(to_base36(v_counter % 1679616), 4, '0');\n")
	sql.WriteString("    \n")
	sql.WriteString("    v_result := v_result || substr(v_fingerprint, 1, 4);\n")
	sql.WriteString("    \n")
	sql.WriteString("    v_random := encode(gen_random_bytes(6), 'hex');\n")
	sql.WriteString("    v_result := v_result || substr(v_random, 1, 8);\n")
	sql.WriteString("    \n")
	sql.WriteString("    RETURN v_result;\n")
	sql.WriteString("END;\n")
	sql.WriteString("$$ LANGUAGE plpgsql VOLATILE;\n\n")

	return sql.String()
}

// ensureDatabaseExists creates the database if it doesn't exist
func (m *AtlasMigrator) ensureDatabaseExists(ctx context.Context) error {
	dbName := extractDatabaseName(m.config.URL)
	if dbName == "" {
		return fmt.Errorf("could not extract database name from URL")
	}

	// Build admin database URL (connect to 'postgres' database)
	adminURL := buildAdminDatabaseURL(m.config.URL)

	// Connect to admin database
	adminConfig := NewDBConfig(adminURL)
	adminDB, err := adminConfig.Connect(ctx)
	if err != nil {
		return fmt.Errorf("failed to connect to admin database: %w", err)
	}
	defer adminDB.Close()

	// Create the database if it doesn't exist
	createSQL := fmt.Sprintf("CREATE DATABASE IF NOT EXISTS %s", quoteIdentifier(dbName))
	fmt.Printf("Creating database if not exists: %s\n", dbName)

	if _, err := adminDB.ExecContext(ctx, createSQL); err != nil {
		return fmt.Errorf("failed to create database %s: %w", dbName, err)
	}

	return nil
}

// buildAdminDatabaseURL builds a URL for connecting to the admin database
func buildAdminDatabaseURL(databaseURL string) string {
	if strings.HasPrefix(databaseURL, "postgres://") || strings.HasPrefix(databaseURL, "postgresql://") {
		parts := strings.Split(databaseURL, "/")
		if len(parts) >= 4 {
			// Replace the database name with 'postgres'
			parts[len(parts)-1] = "postgres"
			if idx := strings.Index(parts[len(parts)-1], "?"); idx != -1 {
				dbPart := parts[len(parts)-1]
				queryPart := dbPart[idx:]
				parts[len(parts)-1] = "postgres" + queryPart
			}
			return strings.Join(parts, "/")
		}
	}
	return databaseURL
}

// extractDatabaseName extracts the database name from a database URL
func extractDatabaseName(databaseURL string) string {
	if strings.HasPrefix(databaseURL, "postgres://") || strings.HasPrefix(databaseURL, "postgresql://") {
		parts := strings.Split(databaseURL, "/")
		if len(parts) >= 4 {
			dbPart := parts[len(parts)-1]
			if idx := strings.Index(dbPart, "?"); idx != -1 {
				return dbPart[:idx]
			}
			return dbPart
		}
	}
	return ""
}
